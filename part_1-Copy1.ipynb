{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I think that some sort of presisten state would be beneficial for the task, as it would help to differentiate similar languages.\n",
    "\n",
    "I didn't manage to successfully train this model, as training was really slow.\n",
    "Wasn't truncating backprob, so if the paragraph was long, the training would slow down a lot.\n",
    "Perhaps I just wasn't using pytorch the right way, as even simple lstm was also taking time to train.\n",
    "\n",
    "I've picked language detection mainly to implement some kind of rnn. And to try pytorch out.\n",
    "\n",
    "After having a look at the data, I've decided NOT to break paragraphs into separate sentences, as there are some citations in original languages. I've noticed this after constructing sets of characters occuring in files in each language category.\n",
    "There were few invisible characters like '/u202e' which I've removed; and some files had chinese characters in them, those were dropped.\n",
    "It also turned out that your test set is a subset of provided data and I didnt bother to filter test set out. Instead I have a separete 'random' subset of data as test.\n",
    "\n",
    "Network has 3 modules, which provide their state information to other modules for some updates.\n",
    "Here is some simplified graphical representation:\n",
    " _______   ____________\n",
    "|Medium | | Long term  |\n",
    "|       |/|____________|\n",
    "|       |\\| Short Term |\n",
    "|______ | |____________|\n",
    "                ^\n",
    "             Inputs\n",
    "             \n",
    "             \n",
    "Each module has some kind of 'attention' to filter inputs, long and short term have 2 states, medium has one.\n",
    "long and short share one of their states with each other, other states are shared via medium (it takes all states as an input). Short term also supposed to output distributed representation of inputs to long term.\n",
    "\n",
    "The network iterates as follows: short term, medium, long term, medium ...\n",
    "\n",
    "For training I predict language every input frame, try to duplicate the first letter of input window from one of short term states, detect the following symbols in the end of the input window (' ', '.', ',') and detect if the input is legit or not, as some inputs are generated by simple gan.\n",
    "Also I try to increase similarity between distributed representations of the same languages.\n",
    "\n",
    "The notebook was run many times, last time I didn't wait to update plots and train bottom lstm model. \n",
    "When training first model, it was goint through one paragraph in ~3 minutes depending on the size of the paragraph.\n",
    "After representation similarity kicked in, was taking about ~20 min per paragraph.\n",
    "\n",
    "LSTM was training at about ~1-2 min per paragraph.\n",
    "\n",
    "\n",
    "ps: file 'pl/ep-09-10-22-009.txt' won't load in python if you were to run the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "os.chdir('txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loading all data in memory, also processing it a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = glob('*')\n",
    "data = []\n",
    "for lang in langs:\n",
    "    os.chdir(lang)\n",
    "    files = glob('*')\n",
    "    counter = 0\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            temp = f.readlines()\n",
    "            for line in temp:\n",
    "                if line[0] != '<':\n",
    "                        line = re.sub(r'\\([CLPNRFHEISDB][GKLNRVEUAISTO]\\)', '', line)    #remove speaker lang annotantions\n",
    "                        line = re.sub(r'[\\xad\\xa0\\u200b\\u202c\\u202e\\u202a\\u202d�]', '', line) #remove invisible chars\n",
    "                        if line[0] != '(':\n",
    "                            if re.search(r'[眠舃舣脘舉]', line) == None:  #drop sentences with chinese chars\n",
    "                                if line[0].isupper() == False:   #try to fix lines which start with lowercase\n",
    "                                    temp2 = line.strip().split('. ')\n",
    "                                    if len(temp2) > 1:\n",
    "                                        line = ''.join([x + '. ' if i != len(temp2) -2 else x for i,x in enumerate(temp2[1:]) ])\n",
    "                                if line[0].isupper() and len(line) < 50 and len(line) > 10: ##dropping long lines to save time\n",
    "                                    ## ok, i've checked how long it takes to go through one paragraph,\n",
    "                                    ## need to drop most of the data or try something else\n",
    "\n",
    "                                    data.append((lang, line.strip()))\n",
    "                                    #if lang = 'es' and counter < 5 and len(line) > 300:\n",
    "                                    #    data.append((lang, line.strip()))\n",
    "                                        \n",
    "    os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the length of data and number of unique symbols (465 symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378339\n"
     ]
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "np.random.shuffle(data)\n",
    "print(len(data))\n",
    "unique_letters = set()\n",
    "for i in range(len(data)):\n",
    "    unique_letters.update(set(data[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data  and making dicts to convert letters and languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:200000] #1kk train\n",
    "val = data[200000:300000] #300K validation\n",
    "test = data[300000:]\n",
    "keys_to_letters = dict(zip(range(len(unique_letters)), list(unique_letters)))\n",
    "letters_to_keys = {val:key for key,val in keys_to_letters.items()}\n",
    "punctuation = [key for key, item in keys_to_letters.items() if item in [' ', '.', ','] ]\n",
    "key_to_lang = dict(zip(range(len(langs)), langs))\n",
    "lang_to_key = {val:key for key,val in key_to_lang.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_to_onehot(letter):\n",
    "    return t.eye(LETTERS_NUM)[letters_to_keys[letter]]\n",
    "\n",
    "def letter_from_onehot(vec):\n",
    "    idx = np.argmax(vec.cpu().numpy())\n",
    "    return keys_to_letters[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining network state sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LETTERS_NUM = len(unique_letters)\n",
    "LANGS_NUM = len(langs)\n",
    "\n",
    "INPUT_WINDOW_SIZE = 10\n",
    "l1_shared = 64\n",
    "l1_not = 64\n",
    "l1_repr = 64\n",
    "l2_shared = 64\n",
    "l2_not = 64\n",
    "l2_repr = 64\n",
    "medium_repr = 64   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "t.set_default_tensor_type('torch.cuda.FloatTensor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### was planning to use this to improve distributetd representations of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GAN(\n",
       "  (layer1): Linear(in_features=71, out_features=100, bias=True)\n",
       "  (mod): Linear(in_features=445, out_features=100, bias=True)\n",
       "  (layer2): Linear(in_features=545, out_features=333, bias=True)\n",
       "  (upd): Linear(in_features=333, out_features=256, bias=True)\n",
       "  (out): Linear(in_features=589, out_features=345, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class GAN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(GAN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Linear(LANGS_NUM + 50, 100)\n",
    "        self.mod = nn.Linear(LETTERS_NUM + 100, 100)\n",
    "        self.layer2 = nn.Linear(200 + LETTERS_NUM, 333)\n",
    "        self.upd = nn.Linear(333, 256)\n",
    "        self.state = t.zeros(256)\n",
    "        self.last_out = t.zeros(LETTERS_NUM)\n",
    "        self.out = nn.Linear(589, LETTERS_NUM)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        prestate = nn.ELU()(self.layer1(inputs))\n",
    "        self.state = self.state * nn.Tanh()(self.mod(t.cat([prestate, self.last_out])))\n",
    "        preupdate = nn.ELU()(self.layer2(t.cat([self.state, prestate, self.last_out])))\n",
    "        self.state = self.state + nn.Tanh()(self.upd(preupdate))\n",
    "        out = nn.Softmax(dim=0)(self.out(t.cat([self.state, preupdate])))\n",
    "        _, index = t.max(out, 0, keepdim=True)\n",
    "        self.last_out = out\n",
    "        letter = t.eye(LETTERS_NUM)[index]\n",
    "        return letter\n",
    "    \n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(1 + np.random.normal()*0.01)    #high bias for update functions\n",
    "\n",
    "garbage_generator = GAN()\n",
    "garbage_generator = garbage_generator.cuda()\n",
    "garbage_generator.apply(init_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function to generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "index_train = 0\n",
    "index_val = 0\n",
    "index_test = 0\n",
    "def gen_data(idx, mode='train', lang_hist=None):\n",
    "    gen_data = []\n",
    "    lang_n = -1\n",
    "    letter = []\n",
    "    punct = []\n",
    "    real = []\n",
    "    gan = 0\n",
    "    data_onehot = []\n",
    "    if mode == 'train' and np.random.rand() > 1:  #not enough time for this\n",
    "        #data = []\n",
    "        gan = 1\n",
    "        lang_n = np.random.randint(0,LANGS_NUM)\n",
    "        lang = key_to_lang[lang_n]\n",
    "        gen_len = np.random.randint(15, 20)\n",
    "        \n",
    "        lang_base = t.eye(LANGS_NUM)[lang_n]\n",
    "        for i in range(gen_len):\n",
    "            seed = t.normal(t.zeros(50), t.ones(50))\n",
    "            feed_in = t.cat([lang_base, seed])\n",
    "            garbage = garbage_generator(feed_in)\n",
    "            data_onehot.append(garbage)\n",
    "        \n",
    "    elif mode =='train':\n",
    "        np.random.shuffle(train)\n",
    "        lang, gen_data = train[idx]\n",
    "        while lang in lang_hist:\n",
    "            idx += 1\n",
    "            lang, gen_data = train[idx]\n",
    "            \n",
    "        lang_hist.append(lang)\n",
    "        data_onehot = [letter_to_onehot(x).view(1,-1) for x in gen_data]\n",
    "    elif mode == 'validation':\n",
    "        lang, gen_data = val[idx]\n",
    "        data_onehot = [letter_to_onehot(x).view(1,-1) for x in gen_data]\n",
    "    else:\n",
    "        lang, gen_data = test[idx]\n",
    "        data_onehot = [letter_to_onehot(x).view(1,-1) for x in gen_data]\n",
    "        #make frames of data\n",
    "    if gan == 1:\n",
    "        n_frames = gen_len - INPUT_WINDOW_SIZE + 1\n",
    "    else:\n",
    "        n_frames = len(gen_data) - INPUT_WINDOW_SIZE + 1\n",
    "    \n",
    "    \n",
    "        \n",
    "    input_frames = t.empty(n_frames, INPUT_WINDOW_SIZE*LETTERS_NUM)\n",
    "    lang = t.ones(n_frames,LANGS_NUM) * t.eye(LANGS_NUM)[lang_to_key[lang]]\n",
    "    letters = t.empty(n_frames, LETTERS_NUM)\n",
    "    punct = t.zeros(n_frames)\n",
    "    \n",
    "    for i in range(n_frames):\n",
    "        letters[i] = data_onehot[i]\n",
    "        input_frames[i] = t.cat(data_onehot[i: i+INPUT_WINDOW_SIZE], dim=1)\n",
    "        if letter_from_onehot(data_onehot[i+INPUT_WINDOW_SIZE-1]) in [' ', ',', '.']:\n",
    "            punct[i] = 1\n",
    "            \n",
    "    if gan == 0:\n",
    "        real = t.ones(n_frames)\n",
    "    else:\n",
    "        real = t.zeros(n_frames)\n",
    "        \n",
    "        \n",
    "    return input_frames, letters, punct, real, lang, lang_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some modules I was palnning to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_n, output_n):\n",
    "        super(Attention, self).__init__()\n",
    "        self.preprocess1 = nn.Linear(input_n, input_n)\n",
    "        self.preprocess2 = nn.Linear(input_n, input_n)\n",
    "        self.mask = nn.Linear(input_n, output_n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.ELU()(self.preprocess1(x))\n",
    "        x = nn.Tanh()(self.preprocess2(x))\n",
    "        x = nn.Sigmoid()(self.mask(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Detector(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_n):\n",
    "        super(Detector, self).__init__()\n",
    "        self.preprocess1 = nn.Linear(input_n, input_n)\n",
    "        self.preprocess2 = nn.Linear(input_n, 16)\n",
    "        self.detector = nn.Linear(16,2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = nn.ELU()(self.preprocess1(x))\n",
    "        x = nn.Tanh()(self.preprocess2(x))\n",
    "        x = nn.Softmax(dim=0)(self.detector(x))\n",
    "        return x\n",
    "\n",
    "class ShortTerm(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_n):\n",
    "        super(ShortTerm, self).__init__()\n",
    "        self.attention = Attention(input_n + l1_shared + l1_not, input_n)\n",
    "        \n",
    "        self.memory_shared = t.zeros(l1_shared) #shared mem is distributed representation of inputs\n",
    "        self.memory = t.zeros(l1_not) #other mem is a state, that is communicated via medium\n",
    "        \n",
    "        \n",
    "        \n",
    "        #shared update\n",
    "        #self.shared_preprocess = nn.Linear()\n",
    "        self.preforget_shared = nn.Linear(input_n + l1_shared + l2_shared, l1_shared + l2_shared)\n",
    "        self.forget_shared = nn.Linear(l1_shared + l2_shared, l1_shared)\n",
    "        self.preupdate_shared = nn.Linear(input_n + l1_shared + l1_not, l1_shared + l1_not)\n",
    "        self.update_shared = nn.Linear(l1_shared + l1_not, l1_shared)\n",
    "        self.process_shared1 = nn.Linear(l1_shared + input_n, l1_repr)\n",
    "        self.process_shared2 = nn.Linear(l1_repr, l1_repr)\n",
    "        \n",
    "        \n",
    "        #other mem update\n",
    "        self.preupdate_mem = nn.Linear(l1_shared + l1_not + medium_repr + l1_shared + l1_not, l1_not + medium_repr)\n",
    "        self.update_mem = nn.Linear(l1_not + medium_repr, l1_not)\n",
    "        \n",
    "        self.last_shared = t.empty(l1_shared)\n",
    "        \n",
    "    def forward(self, obs, shared, medium):\n",
    "        \n",
    "        #get new observation to passs through attention\n",
    "        attention =  self.attention(t.cat([obs, self.memory_shared, self.memory]))\n",
    "        obs = obs * attention\n",
    "        #save old shared state for updates\n",
    "        self.last_shared = self.memory_shared\n",
    "        \n",
    "        #update shared_mem\n",
    "        preforget_shared = nn.ELU()(self.preforget_shared(t.cat([obs, self.last_shared, shared])))\n",
    "        forget_shared = nn.Sigmoid()(self.forget_shared(preforget_shared))\n",
    "        self.memory_shared = self.memory_shared * forget_shared\n",
    "        \n",
    "        preupdate_shared = nn.ELU()(self.preupdate_shared(t.cat([obs, self.last_shared, self.memory])))\n",
    "        update_shared = nn.Tanh()(self.update_shared(preupdate_shared))\n",
    "        \n",
    "        self.memory_shared = self.memory_shared + update_shared\n",
    "        \n",
    "        processed = nn.ELU()(self.process_shared1(t.cat([obs, self.memory_shared])))\n",
    "        processed = nn.Tanh()(self.process_shared2(processed))\n",
    "        #update other mem\n",
    "        \n",
    "        preupdate = nn.ELU()(self.preupdate_mem(t.cat([self.memory, self.memory_shared, medium, preupdate_shared])))\n",
    "        update = nn.Tanh()(self.update_mem(preupdate))\n",
    "        self.memory = self.memory * update\n",
    "        \n",
    "        return self.memory, self.memory_shared, processed\n",
    "    \n",
    "class LongTerm(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_n):\n",
    "        super(LongTerm, self).__init__()\n",
    "        self.attention = Attention(input_n + l2_shared + l2_not + l1_shared, input_n)\n",
    "        \n",
    "        self.memory_shared = t.zeros(l2_shared) #shared mem is distributed representation of inputs\n",
    "        self.memory = t.zeros(l2_not) #other mem is a state, that is communicated via medium\n",
    "        \n",
    "        #shared update\n",
    "        self.preforget_shared = nn.Linear(input_n + l1_shared + l2_shared, l1_shared + l2_shared)\n",
    "        self.forget_shared = nn.Linear(l1_shared + l2_shared, l2_shared)\n",
    "        self.preupdate_shared = nn.Linear(input_n + l2_shared + l2_not, l2_shared + l2_not)\n",
    "        self.update_shared = nn.Linear(l2_shared + l2_not, l2_shared)\n",
    "        self.process_shared1 = nn.Linear(l2_shared + input_n, l2_repr)\n",
    "        self.process_shared2 = nn.Linear(l2_repr, l2_repr)\n",
    "        \n",
    "        \n",
    "        #other mem update\n",
    "        self.preupdate_mem = nn.Linear(2*l2_shared + 2*l2_not + medium_repr, l2_shared + l2_not + medium_repr)\n",
    "        self.update_mem = nn.Linear(l2_shared + l2_not + medium_repr, l2_not)\n",
    "        \n",
    "        self.last_shared = t.empty(l2_shared)\n",
    "        \n",
    "    \n",
    "    def forward(self, obs, shared, medium):\n",
    "        \n",
    "        #get new observation to passs through attention\n",
    "        attention =  self.attention(t.cat([shared, self.memory_shared, self.memory, obs]))\n",
    "        obs = obs * attention\n",
    "        \n",
    "        #save old shared state for updates\n",
    "        self.last_shared = self.memory_shared\n",
    "        \n",
    "        #update shared_mem\n",
    "        preforget_shared = nn.ELU()(self.preforget_shared(t.cat([obs, self.last_shared, shared])))\n",
    "        forget_shared = nn.Sigmoid()(self.forget_shared(preforget_shared))\n",
    "        self.memory_shared = self.memory_shared * forget_shared\n",
    "        \n",
    "        preupdate_shared = nn.ELU()(self.preupdate_shared(t.cat([obs, self.last_shared, self.memory])))\n",
    "        update_shared = nn.Tanh()(self.update_shared(preupdate_shared))\n",
    "        self.memory_shared = self.memory_shared + update_shared\n",
    "        \n",
    "        \n",
    "        processed = nn.ELU()(self.process_shared1(t.cat([obs, self.memory_shared])))\n",
    "        processed = nn.Tanh()(self.process_shared2(processed))\n",
    "        #update other mem\n",
    "        \n",
    "        preupdate = nn.ELU()(self.preupdate_mem(t.cat([self.memory, self.memory_shared, medium, preupdate_shared])))\n",
    "        update = nn.Tanh()(self.update_mem(preupdate))\n",
    "        self.memory = self.memory * update\n",
    "        \n",
    "        return self.memory, self.memory_shared, processed\n",
    "    \n",
    "    \n",
    "class Medium(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_n):\n",
    "        super(Medium, self).__init__()\n",
    "        self.attention = Attention(input_n + medium_repr, input_n)\n",
    "        self.medium = t.zeros(medium_repr)\n",
    "        self.preforget = nn.Linear(input_n + medium_repr, medium_repr)\n",
    "        self.forget = nn.Linear(medium_repr, medium_repr)\n",
    "        self.preupdate = nn.Linear(input_n + medium_repr + l1_shared + l2_shared + medium_repr, 2*medium_repr)\n",
    "        self.update = nn.Linear(2*medium_repr, medium_repr)\n",
    "        self.last_state = t.empty(medium_repr)\n",
    "        \n",
    "    def forward(self, st_mem, st_shared, lt_mem, lt_shared):\n",
    "        #Input attention\n",
    "        obs = t.cat([st_mem, st_shared, lt_mem, lt_shared])\n",
    "        attention = self.attention(t.cat([obs, self.medium]))\n",
    "        obs = obs * attention\n",
    "        \n",
    "        #Medium updates\n",
    "        self.last_state = self.medium\n",
    "        preforget = nn.ELU()(self.preforget(t.cat([obs, self.medium])))\n",
    "        forget = nn.Sigmoid()(self.forget(preforget))\n",
    "        self.medium = self.medium * forget\n",
    "        \n",
    "        preupdate = nn.ELU()(self.preupdate(t.cat([obs, self.last_state, st_shared, lt_shared, preforget])))\n",
    "        update = nn.Tanh()(self.update(preupdate))\n",
    "        self.medium = self.medium + update\n",
    "        return self.medium\n",
    "    \n",
    "\n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_n, out_n):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_n, input_n)\n",
    "        self.layer2 = nn.Linear(input_n, input_n)\n",
    "        self.layer3 = nn.Linear(input_n, out_n)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        preprocess = nn.ELU()(self.layer1(inputs))\n",
    "        representation = nn.Tanh()(self.layer2(preprocess))\n",
    "        guess = nn.Softmax(dim=0)(self.layer3(representation))\n",
    "        \n",
    "        return guess\n",
    "        \n",
    "\n",
    "class LanguageDetector(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LanguageDetector, self).__init__()\n",
    "        \n",
    "        #Modules\n",
    "        self.short_term = ShortTerm(LETTERS_NUM*INPUT_WINDOW_SIZE)\n",
    "        self.long_term = LongTerm(l1_repr)\n",
    "        self.medium = Medium(l1_shared + l1_not + l2_shared + l2_not)\n",
    "        self.current_letter = Decoder(l1_shared + l1_repr, LETTERS_NUM)\n",
    "        self.punctuation = Detector(l1_not + l1_repr) \n",
    "        self.word_real = Detector(l2_shared + l2_not + medium_repr)\n",
    "        self.lang = Decoder(l2_shared + l2_not + medium_repr + l2_repr, LANGS_NUM)\n",
    "        \n",
    "        #Variables \n",
    "        self.medium_state = self.medium.medium\n",
    "        self.short_term_shared = self.short_term.memory_shared\n",
    "        self.short_term_mem = self.short_term.memory\n",
    "        self.long_term_shared = self.long_term.memory_shared\n",
    "        self.long_term_mem = self.long_term.memory\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        #Short_term pass through\n",
    "        \n",
    "        self.short_term_mem, self.short_term_shared, data1 = self.short_term(inputs,\\\n",
    "                                                                      self.long_term_shared, self.medium_state)\n",
    "        \n",
    "        \n",
    "        #Medium update\n",
    "        \n",
    "        self.medium_state = self.medium(self.short_term_mem, self.short_term_shared,\\\n",
    "                                       self.long_term_mem, self.long_term_shared)\n",
    "        \n",
    "        #long_term pass through\n",
    "        self.long_term_mem, self.long_term_shared, data2 = self.long_term(data1,\\\n",
    "                                                                   self.short_term_shared, self.medium_state)\n",
    "        \n",
    "        #Another medium update\n",
    "        \n",
    "        self.medium_state = self.medium(self.short_term_mem, self.short_term_shared,\\\n",
    "                                       self.long_term_mem, self.long_term_shared)\n",
    "        \n",
    "        \n",
    "        #Inference\n",
    "        current_letter = self.current_letter(t.cat([self.short_term_shared, data1]))\n",
    "        punctuation = self.punctuation(t.cat([self.short_term_mem, data1]))\n",
    "        \n",
    "        word_real = self.word_real(t.cat([self.long_term_shared, self.long_term_mem, self.medium_state]))\n",
    "        lang = self.lang(t.cat([self.medium_state, self.long_term_mem, self.long_term_shared, data2]))\n",
    "        \n",
    "        return lang, current_letter, punctuation, word_real, data1, data2 #nevermind word_real, should've been renamed\n",
    "\n",
    "    \n",
    "#setting low bias for forget gates and high bias for update \n",
    "    \n",
    "net = LanguageDetector()\n",
    "net = net.cuda()\n",
    "net.apply(init_weights)\n",
    "net.short_term.preforget_shared.bias.data.fill_(0)\n",
    "net.short_term.forget_shared.bias.data.fill_(0)\n",
    "net.long_term.preforget_shared.bias.data.fill_(0)\n",
    "net.long_term.forget_shared.bias.data.fill_(0)\n",
    "net.medium.preforget.bias.data.fill_(0)\n",
    "net.medium.forget.bias.data.fill_(0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "language_loss = nn.CrossEntropyLoss()   #main loss\n",
    "letter_loss = nn.CrossEntropyLoss()#net supposed to decode first letter of input from state of shrt_trm and its output\n",
    "real_word_loss = nn.CrossEntropyLoss()#to train gan\n",
    "punctuation = nn.CrossEntropyLoss()#similar to letter loss but from different state and at the end of input window\n",
    "repr1_loss = nn.CosineSimilarity(dim=0) #increase similarity of shrt_term outputs for same languages\n",
    "repr2_loss = nn.CosineSimilarity(dim=0)#same but for long_term\n",
    "\n",
    "gan_optimizer = t.optim.RMSprop(garbage_generator.parameters(), lr=0.001, momentum=0.6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### few more helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tqdm import trange\n",
    "\n",
    "def reset_lang():\n",
    "    net.short_term.memory = t.zeros(l1_not)\n",
    "    net.short_term.memory_shared = t.zeros(l1_shared)\n",
    "    net.long_term.memory = t.zeros(l2_not)\n",
    "    net.long_term.memory_shared = t.zeros(l2_shared)\n",
    "    net.medium.medium = t.zeros(medium_repr)\n",
    "    net.medium_state = net.medium.medium\n",
    "    net.short_term_shared = net.short_term.memory_shared\n",
    "    net.short_term_mem = net.short_term.memory\n",
    "    net.long_term_shared = net.long_term.memory_shared\n",
    "    net.long_term_mem = net.long_term.memory\n",
    "    \n",
    "def evaluate():\n",
    "    with t.no_grad():\n",
    "        reset_lang()\n",
    "        acc = []\n",
    "        np.random.shuffle(val)\n",
    "        for q in range(50):\n",
    "            input_frames, letters, punct, real, lang, lang_hist = gen_data(q, mode='validation')\n",
    "            predictions = t.zeros(LANGS_NUM)\n",
    "            ans = t.ones_like(lang[0]) * -1\n",
    "            for i in range(len(letters)):\n",
    "                l, _,_,_,_,_ = net(input_frames[i])\n",
    "                predictions = predictions + l\n",
    "            _, ans = t.max(predictions,0)\n",
    "            _, lang = t.max(lang[0],0)\n",
    "            if ans == lang:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "            reset_lang()   \n",
    "        return sum(acc)/len(acc)\n",
    "        \n",
    "#evaluate()\n",
    "#print(net.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "\n",
    "#plt.show()\n",
    "fig, axs = plt.subplots(2,1, figsize=(15,7))\n",
    "    \n",
    "#training\n",
    "from tqdm import trange\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "repr1_hist = t.zeros(LANGS_NUM,l1_repr)\n",
    "repr2_hist = t.zeros(LANGS_NUM,l2_repr)\n",
    "index_train = 0\n",
    "\n",
    "\n",
    "def detach_lang():\n",
    "    net.short_term.memory = net.short_term.memory.detach()\n",
    "    net.short_term.memory_shared = net.short_term.memory_shared.detach() \n",
    "    net.long_term.memory = net.long_term.memory.detach()\n",
    "    net.long_term.memory_shared = net.long_term.memory_shared.detach\n",
    "    net.medium.medium = net.medium.medium.detach()\n",
    "    net.medium_state = net.medium_state.detach()\n",
    "    net.short_term_shared = net.short_term_shared.detach()\n",
    "    net.short_term_mem = net.short_term_mem.detach()\n",
    "    net.long_term_shared = net.long_term_shared.detach()\n",
    "    net.long_term_mem = net.long_term_mem.detach()\n",
    "\n",
    "def reset_gan():\n",
    "    garbage_generator.state = t.zeros(256)\n",
    "    \n",
    "loss_history = []\n",
    "gan_loss_history = []\n",
    "val_acc = []\n",
    "lang_hist = []\n",
    "for epoch in range(num_epochs):\n",
    "    np.random.shuffle(train)\n",
    "    for i in range(5000):\n",
    "        reset_lang()\n",
    "        if len(lang_hist) == 21:\n",
    "            lang_hist = []\n",
    "        input_frames, letters, punct, real, lang, lang_hist = gen_data(i, lang_hist=lang_hist)\n",
    "        temp_loss = 0\n",
    "        temp_gan_loss = 0\n",
    "        \n",
    "        for q in range(len(letters)):\n",
    "            temp1 = np.argmax(lang[q].cpu().numpy())\n",
    "            temp2 = temp1.copy()\n",
    "            while temp2 == temp1:\n",
    "                temp2 = np.random.randint(0,LANGS_NUM)\n",
    "            \n",
    "            detected_lang, detected_letter, detected_punct, detected_real, repr1, repr2 = net(input_frames[q])\n",
    "            \n",
    "            lang_loss1 = language_loss(detected_lang.view((1,-1)), lang[q].max(0)[1].long().view(1)) \n",
    "            lang_loss2 =  letter_loss(detected_letter.view((1,-1)), letters[q].max(0)[1].long().view(1)) \n",
    "            lang_loss3 = punctuation(detected_punct.view((1,-1)), punct[q].long().view(1))\n",
    "            lang_loss4 = real_word_loss(detected_real.view((1,-1)), real[q].long().view(1))\n",
    "            lang_loss5 = F.cosine_similarity(repr1, repr1_hist[temp2], dim=0) - F.cosine_similarity(repr1, repr1_hist[temp1], dim=0)\n",
    "            lang_loss6 = F.cosine_similarity(repr2, repr2_hist[temp2], dim=0) - F.cosine_similarity(repr2, repr2_hist[temp1], dim=0)\n",
    "            #if i > 20:\n",
    "            #    lang_loss = lang_loss1 + lang_loss2 + lang_loss3 + lang_loss4 + lang_loss5 + lang_loss6\n",
    "            #else:\n",
    "            lang_loss = lang_loss1 + lang_loss2 + lang_loss3 + lang_loss4\n",
    "            if real[0] == t.zeros(1):\n",
    "                gan_loss = language_loss(detected_lang.view((1,-1)), lang[q].max(0)[1].long().view(1)) + letter_loss(detected_letter.view((1,-1)), letters[q].max(0)[1].long().view(1)) + \\\n",
    "                punctuation(detected_punct.view((1,-1)), punct[q].long().view(1)) + real_word_loss(detected_real.view((1,-1)), t.ones(1).long().view(1)) +\\\n",
    "                F.cosine_similarity(repr1, repr1_hist[temp2], dim=0) - F.cosine_similarity(repr1, repr1_hist[temp1], dim=0) +\\\n",
    "                F.cosine_similarity(repr2, repr2_hist[temp2], dim=0) - F.cosine_similarity(repr2, repr2_hist[temp1], dim=0)\n",
    "            else:\n",
    "                gan_loss = 0\n",
    "                \n",
    "            \n",
    "            lang_optimizer.zero_grad()\n",
    "            #gan_optimizer.zero_grad()\n",
    "            \n",
    "            lang_loss.backward(retain_graph=True)\n",
    "            lang_optimizer.step()\n",
    "            \n",
    "            #if gan_loss != 0:\n",
    "            #    gan_loss.backward(retain_graph=True)\n",
    "            #    gan_optimizer.step()\n",
    "            #    temp_gan_loss += gan_loss\n",
    "                \n",
    "            temp_loss += lang_loss.item()\n",
    "            \n",
    "            #\n",
    "            #if q %10 == 0:\n",
    "            #    detach_lang()\n",
    "            #    reset_lang()\n",
    "                \n",
    "                \n",
    "            repr1_hist[temp1] = repr1.clone()\n",
    "            repr2_hist[temp1] = repr2.clone()\n",
    "        detach_lang()\n",
    "        reset_lang()\n",
    "        reset_gan()\n",
    "\n",
    "        if i % 10 == 0:# and temp_gan_loss != 0: \n",
    "            loss_history.append(temp_loss/(q+1))\n",
    "            val_acc.append(evaluate())\n",
    "            #gan_loss_history.append(temp_gan_loss/(q+1))\n",
    "            axs[0].plot(loss_history)\n",
    "            axs[1].plot(val_acc)\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training slows down a lot when representations similarity kicks in (like 10-20x)\n",
    "However it's very slow even without representation losses\n",
    "\n",
    "It's almost deadline, will just train lstm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simple(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Simple, self).__init__()\n",
    "        self.embedding = nn.Linear(LETTERS_NUM*INPUT_WINDOW_SIZE, 128) #semi embedding\n",
    "        self.lstm = nn.LSTM(128,128, 2)\n",
    "        self.preout = nn.Linear(128,64)\n",
    "        self.out = nn.Linear(64,LANGS_NUM)\n",
    "        self.hidden = t.zeros(2,1,128)\n",
    "        self.last = t.zeros(2,1,128)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeddings = nn.ELU()(self.embedding(inputs))\n",
    "        embeddings = embeddings.view(embeddings.size()[0], 1, embeddings.size()[1])\n",
    "        lstm_out, (self.hidden, self.last) = self.lstm(embeddings, (self.hidden, self.last))\n",
    "        preout = nn.ELU()(self.preout(lstm_out))\n",
    "        out = nn.Softmax(dim = 2)(self.out(preout))\n",
    "        return out\n",
    "    \n",
    "\n",
    "    \n",
    "net2 = Simple()\n",
    "net2.apply(init_weights)\n",
    "net2 = net2.cuda()\n",
    "\n",
    "def reset_net2():\n",
    "    net2.hidden = net2.hidden.detach()\n",
    "    net2.last = net2.last.detach()\n",
    "    net2.hidden = t.zeros(2,1,128)\n",
    "    net2.last = t.zeros(2,1,128)\n",
    "    \n",
    "def evaluate_simple():\n",
    "    with t.no_grad():\n",
    "        reset_net2()\n",
    "        acc = []\n",
    "        np.random.shuffle(val)\n",
    "        for q in range(100):\n",
    "            \n",
    "            input_frames, _, _, _, lang, lang_hist = gen_data(q, mode='validation')\n",
    "            predictions = t.zeros(LANGS_NUM)\n",
    "            ans = t.ones_like(lang[0]) * -1\n",
    "            l = net2(input_frames)\n",
    "            predictions = t.sum(l, 0)\n",
    "            _, ans = t.max(predictions,1)\n",
    "            _, lang = t.max(lang[0],0)\n",
    "            if ans[0] == lang:\n",
    "                acc.append(1)\n",
    "            else:\n",
    "                acc.append(0)\n",
    "            reset_net2()   \n",
    "        return sum(acc)/len(acc)\n",
    "    \n",
    "#evaluate_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-695c34ab6eda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-9>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[1;32m   2261\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2263\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m   2264\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# if toolbar:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;31m#     toolbar.set_cursor(cursors.WAIT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1475\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2605\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2607\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2609\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_dashes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dashOffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dashSeq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maffine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrozen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m                 \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw_path\u001b[0;34m(self, gc, path, transform, rgbFace)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_renderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrgbFace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOverflowError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 raise OverflowError(\"Exceeded cell block limit (set \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "lang_optimizer = t.optim.Adam(net2.parameters(), lr=3e-5)#, amsgrad=True)\n",
    "#lang_optimizer = t.optim.SGD(net2.parameters(), lr=1e-4, momentum=0.8, weight_decay=1e-7)\n",
    "\n",
    "num_epochs = 1\n",
    "fig, axs = plt.subplots(2,1, figsize=(15,7))\n",
    "\n",
    "\n",
    "repr1_hist = t.zeros(LANGS_NUM,l1_repr)\n",
    "repr2_hist = t.zeros(LANGS_NUM,l2_repr)\n",
    "index_train = 0\n",
    "\n",
    "loss_history = []\n",
    "gan_loss_history = []\n",
    "val_acc = []\n",
    "plot_x = [0]\n",
    "lang_hist = []\n",
    "loss_calculator = nn.CrossEntropyLoss()\n",
    "for epoch in range(num_epochs):\n",
    "    np.random.shuffle(train)\n",
    "    for i in range(500):\n",
    "        reset_net2()\n",
    "        if len(lang_hist) == 21:\n",
    "            lang_hist = []\n",
    "        input_frames, _, _, _, lang, lang_hist = gen_data(i, lang_hist=lang_hist)\n",
    "        temp_loss = 0\n",
    "        temp_gan_loss = 0\n",
    "        for q in range(len(lang)):\n",
    "            temp1 = np.argmax(lang[q].cpu().numpy())\n",
    "            temp2 = temp1.copy()\n",
    "            while temp2 == temp1:\n",
    "                temp2 = np.random.randint(0,LANGS_NUM)\n",
    "            \n",
    "            lang_prediction = net2(input_frames)\n",
    "            lang_loss = loss_calculator(lang_prediction.view((1,-1)), lang[q].max(0)[1].long().view(1))\n",
    "            lang_optimizer.zero_grad()\n",
    "            \n",
    "            lang_loss.backward(retain_graph=True)\n",
    "            lang_optimizer.step()\n",
    "            \n",
    "            temp_loss += lang_loss.item()\n",
    "            axs[0].plot(loss_history)\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "        \n",
    "            loss_history.append(lang_loss.item())   \n",
    "        reset_net2()\n",
    "\n",
    "        if i % 100 == 0:# and temp_gan_loss != 0:    \n",
    "            \n",
    "            #gan_loss_history.append(temp_gan_loss/(q+1))\n",
    "            val_acc.append(evaluate_simple())\n",
    "            axs[1].plot(val_acc)\n",
    "            #plt.plot(gan_loss_history)\n",
    "            axs[0].plot(loss_history, color='green')\n",
    "            display.clear_output(wait=True)\n",
    "            display.display(plt.gcf())\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Somehow lstm trains not much faster than my network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some results will be in the bottom of another notebook (part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
